{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now implement the perceptron classifier. We put ourselves in a setting where we have access to training examples $\\boldsymbol{x}_i$ and each of them is associated with a target $y\\in{-1,1}$. \n",
    "\n",
    "The perceptron classifier is a simple model that consists of a single neuron with a step activation function (also known as a [heavyside step function](https://en.wikipedia.org/wiki/Heaviside_step_function)).\n",
    "\n",
    "One can visualize it as follows:\n",
    "![The Perceptron](./scripts/perceptron.png)\n",
    "\n",
    "If you have questions or comments : charlotte[dot]laclau[at]univ-grenoble-alpes[dot]fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation\n",
    "Given an n-dimensional input $x\\in\\mathbb{R}^n$ and taking into account the bias unit, one moves from the input to the output with two steps: \n",
    "- $s= \\sum\\limits_{i=0}^n w_ix_i$, where for consistency assume that the bias unit is $x_0$\n",
    "- Application of the step function on s, that is\n",
    "$a = \\begin{cases} \n",
    "      1 & s\\geq 0 \\\\\n",
    "      -1 & s < 0 \n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error propagation\n",
    "\n",
    "Repeat until max_epochs or convergence is reached:\n",
    "\n",
    "For each example in the training set:   \n",
    "1. Forward pass to calculate $a$\n",
    "3. If the example is misclassified: update each of the  weights $i$ with: $w_i^{(t+1)} = w_i^{(t)} + \\eta*x_i*y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why these update equations?\n",
    "We are in the standard supervised classification setting, where one has $k$ examples $\\vec{X}={\\vec{x_1}, \\ldots, \\vec{x_k}}$, where $\\vec{x_k} \\in \\mathbb{R}^n$. Each $\\vec{x}_k \\in \\vec{X}$ is associated with a category $y_k \\in \\mathbb{Y}$, from a pre-defined set of categories. In the binary case $\\mathbb{Y}=\\{-1, +1\\}$.  \n",
    "\n",
    "We then, want to learn a vector $\\vec{w} \\in \\mathbb{R}^{n+1}$, to perform the above described classification step. For the weight vector $\\vec{w}$ we moved from $n$ to $n+1$ dimensions to account for the bias unit.\n",
    "Using the perceptron algorithm we want to minimize the number of examples we misclassify, and essentially if the examples are linearly separable, misclassify nothing. Hence, one can define a simple loss function:\n",
    "\n",
    "$\\mathbb{L} = -\\sum\\limits_{k} y_k(\\vec{w}\\cdot\\vec{x_k})$ \n",
    "\n",
    "In the online case, where one updates the weights for a single instance $k$, this becomes:\n",
    "$\\mathbb{L} = - y_k(\\vec{w}\\cdot\\vec{x_k})$, where  L\n",
    "\n",
    "To change the direction of $\\vec{w}$ when we misclassify, we can:\n",
    "\n",
    "$\\nabla L = \\frac{\\partial L}{\\partial w}= - y_k x_k$\n",
    "\n",
    "We scale this update using the learning rate $\\eta$ and we update by taking a step towards the negative of the gradient:\n",
    "\n",
    "$w_k^{(t+1)} = w_k^{(t)} + \\eta*x_k*y_k$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next steps\n",
    "TBD: \n",
    "\n",
    "1. create a simple training set like the OR function\n",
    "2. Learn the OR function\n",
    "\n",
    "Pseudo-code : \n",
    "`input: X, Y, eta, w, n\n",
    "for i in 1:n\n",
    "    pick an example randomly\n",
    "    result <- w*x\n",
    "    if (result<0)\n",
    "        result=0 \n",
    "    else \n",
    "        result =1\n",
    "    error <- Y - result \n",
    "    w <- w + eta*error*x`\n",
    "\n",
    "(indication: the if statement could be defined as a function beforehand in a step function)\n",
    "3. We are now going to work on the sonar.txt dataset. \n",
    "    1. Download the dataset using the read_table function of the pandas librairy. This will create a dataframe (same than in R). Before starting, you can check the size of the data or other basic statistics (head, shape, etc.). The last column contains the class of each object. \n",
    "    2. Separate the features from the target (see loc); Transform the target into numeric values. \n",
    "    3. Split the dataset into train and test files (see train_test_split)  \n",
    "    4. Use the perceptron classifier available in sckit-learn. The function presents a lot of options that you should explore. \n",
    "    \n",
    "    5. Repeat the same operations but using K-folds instead of one train and one test file.\n",
    "    \n",
    "4. If you feel comfortable with Python, code the perceptron classifier \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to ckeck: `np.array`, `numpy.random.rand`, `numpy.dot`,  `random.choice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random, numpy as np, matplotlib.pyplot as plt, time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]: -0.04574258185339358 -> 0\n",
      "[0 1]: 0.47352494545658447 -> 1\n",
      "[1 0]: 0.6756688557541826 -> 1\n",
      "[1 1]: 1.1949363830641606 -> 1\n"
     ]
    }
   ],
   "source": [
    "# Training data for the first question\n",
    "training_data = [\n",
    "    (np.array([0,0,1]), 0),\n",
    "    (np.array([0,1,1]), 1),\n",
    "    (np.array([1,0,1]), 1),\n",
    "    (np.array([1,1,1]), 1),\n",
    "]\n",
    "\n",
    "\n",
    "def unit_step(value):\n",
    "    if value < 0:\n",
    "        return 0 \n",
    "    else: \n",
    "        return 1\n",
    "   \n",
    "    #  or unit_step = lambda x: 0 if x <0 else 1\n",
    "n = 20 \n",
    "eta = 0.2 \n",
    "errors = []\n",
    "w = np.random.rand(3)\n",
    "\n",
    "for i in range(n):\n",
    "    x, expected = random.choice(training_data)\n",
    "    result = np.dot(w,x)\n",
    "    error = expected - unit_step(result)\n",
    "    w += eta*error*x\n",
    "    errors.append(error)\n",
    "    \n",
    "for x, _ in training_data:\n",
    "    result = np.dot(x, w)\n",
    "    print(\"{}: {} -> {}\".format(x[:2], result, unit_step(result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9  ...      51      52      53      54      55      56      57      58  \\\n",
       "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
       "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "\n",
       "       59  60  \n",
       "0  0.0032   R  \n",
       "1  0.0044   R  \n",
       "2  0.0078   R  \n",
       "3  0.0117   R  \n",
       "4  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 1\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import Perceptron\n",
    "import pandas as pd \n",
    "\n",
    "# Load dataset \n",
    "sonar = pd.read_table('sonar.txt', header = None, delimiter=',')\n",
    "sonar.head()\n",
    "\n",
    "\n",
    "# In case of missing values, you can remove NaN elements using dropna function\n",
    "# sonar = sonar.dropna(how=\"any\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: pre-processing\n",
    "\n",
    "\n",
    "Before splitting the data into the test and the train set, you should check if you need to normalise the data. Usually, it is necessary if the scales of the variables are two different from one another. For the sonar data, all variables have values between 0 and 1, so it's fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: ['M' 'R']\n"
     ]
    }
   ],
   "source": [
    "# Import the function for splitting the data from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Separate data from label. To access elements of a dataframe using the position, use .loc \n",
    "x = sonar.loc[:,range(60)]\n",
    "target = sonar.loc[:,60]\n",
    "\n",
    "# Use unique function to describe the possible labels \n",
    "print(\"Unique labels: {0}\".format(np.unique(target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data: random_state allow you to control the randomness of your training and test set. Here I set it to 0 (it could be any integer of your choice)\n",
    "By doing so, everytime that I run de following lines, if random_state is at 0, I will create the same train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "# test_size indicates the proportion of the instances which are used of the test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, target, test_size=0.20, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Finally the perceptron!\n",
    "\n",
    "Create the perceptron instance. This simply creates the model structure with the given hyper-parameters (options)\n",
    "I set some of the options of the perceptron: maximum number of iterations and learning step\n",
    "You also have options about regularisation to avoid overfitting (check it in the documentation of the perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options - hyperparameters\n",
    "max_iter = 10\n",
    "eta0= 0.1\n",
    "\n",
    "# Create the perceptron instance. Again the random state (controls the random initialisation of weights) \n",
    "clf = Perceptron(max_iter = max_iter, eta0=eta0, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the perceptron on the training instances. In this case, the model uses both the example and the label to learn the weights. This is crucial but will not give any information about the generalization capacity of you model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=0.1, fit_intercept=True,\n",
       "      max_iter=10, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 :  Train the perceptron on the training instances. In this case, the model uses both the example and the label to learn the weights. This is crucial but will not give any information about the generalization capacity of you model. To evaluate the true efficiency of the classifier, I will use it to predict the labels of the test set, which was not use when the model was trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: evaluate the performance in terms of accuracy. The accuracy is simply the proportion of labels that are correctly predicted by your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 80.95%\n"
     ]
    }
   ],
   "source": [
    "# Measure the performance using the accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"accuracy: {0:.2f}%\".format(accuracy_score(y_test, y_pred)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
